{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/octoopt/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moctoopt\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    top_k_accuracy_score,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from huggingface_hub import login\n",
    "import wandb\n",
    "\n",
    "DATASET_ID = \"minhleduc/multilang-classify-dataset-02\"\n",
    "MODEL_NAMES = {\n",
    "    \"xlm-roberta\": \"FacebookAI/xlm-roberta-base\",\n",
    "    \"mbert\": \"google-bert/bert-base-multilingual-cased\",\n",
    "    \"distilbert-multilingual\": \"distilbert/distilbert-base-multilingual-cased\",\n",
    "    \"deberta-v3\": \"microsoft/mdeberta-v3-base\",\n",
    "    \"rembert\": \"google/rembert\",\n",
    "}\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"),\n",
    "                )\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Language', 'Text'],\n",
      "        num_rows: 83358\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['Language', 'Text'],\n",
      "        num_rows: 17862\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['Language', 'Text'],\n",
      "        num_rows: 17863\n",
      "    })\n",
      "})\n",
      "\n",
      "Dataset info:\n",
      "Number of splits: 3\n",
      "train: 83358 examples\n",
      "validation: 17862 examples\n",
      "test: 17863 examples\n",
      "\n",
      "First 3 examples from train split:\n",
      "Example 1:\n",
      "  Language: 28\n",
      "  Text: wa wa nasaha walevi could ya wagonjwa wa wamelewa wamelewa\n",
      "\n",
      "Example 2:\n",
      "  Language: 35\n",
      "  Text: vĩnh viễn quảng cáo tỷ lệ tăng trưởng gdp sẽ yêu cầu bao giờ tăng các lượt chia sẻ tương đối của lưu...\n",
      "\n",
      "Example 3:\n",
      "  Language: 33\n",
      "  Text: özellikle şehrin en ünlü sakinleri olan geyşa nın son eğitim merkezi olarak ünlü\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(DATASET_ID)\n",
    "print(\"Dataset structure:\")\n",
    "print(dataset)\n",
    "print(\"\\nDataset info:\")\n",
    "print(f\"Number of splits: {len(dataset)}\")\n",
    "for split_name, split_data in dataset.items():\n",
    "    print(f\"{split_name}: {len(split_data)} examples\")\n",
    "\n",
    "# Show first few examples\n",
    "print(\"\\nFirst 3 examples from train split:\")\n",
    "for i in range(min(3, len(dataset[\"train\"]))):\n",
    "    print(f\"Example {i + 1}:\")\n",
    "    example = dataset[\"train\"][i]\n",
    "    for key, value in example.items():\n",
    "        if isinstance(value, str) and len(value) > 100:\n",
    "            print(f\"  {key}: {value[:100]}...\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset[\"train\"]\n",
    "val_ds = dataset[\"validation\"]\n",
    "test_ds = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_index = {\n",
    "    0: {\"code\": \"ar\", \"name\": \"Arabic\"},\n",
    "    1: {\"code\": \"bg\", \"name\": \"Bulgarian\"},\n",
    "    2: {\"code\": \"zh-cn\", \"name\": \"Chinese (Simplified)\"},\n",
    "    3: {\"code\": \"da\", \"name\": \"Danish\"},\n",
    "    4: {\"code\": \"nl\", \"name\": \"Dutch\"},\n",
    "    5: {\"code\": \"en\", \"name\": \"English\"},\n",
    "    6: {\"code\": \"et\", \"name\": \"Estonian\"},\n",
    "    7: {\"code\": \"fr\", \"name\": \"French\"},\n",
    "    8: {\"code\": \"de\", \"name\": \"German\"},\n",
    "    9: {\"code\": \"el\", \"name\": \"Greek\"},\n",
    "    10: {\"code\": \"hi\", \"name\": \"Hindi\"},\n",
    "    11: {\"code\": \"id\", \"name\": \"Indonesian\"},\n",
    "    12: {\"code\": \"it\", \"name\": \"Italian\"},\n",
    "    13: {\"code\": \"ja\", \"name\": \"Japanese\"},\n",
    "    14: {\"code\": \"kn\", \"name\": \"Kannada\"},\n",
    "    15: {\"code\": \"ko\", \"name\": \"Korean\"},\n",
    "    16: {\"code\": \"it\", \"name\": \"Italian\"},\n",
    "    17: {\"code\": \"ml\", \"name\": \"Malayalam\"},\n",
    "    18: {\"code\": \"el\", \"name\": \"Greek\"},\n",
    "    19: {\"code\": \"fa\", \"name\": \"Persian\"},\n",
    "    20: {\"code\": \"pl\", \"name\": \"Polish\"},\n",
    "    21: {\"code\": \"pt\", \"name\": \"Portuguese\"},\n",
    "    22: {\"code\": \"pt\", \"name\": \"Portuguese\"},\n",
    "    23: {\"code\": \"pt\", \"name\": \"Portuguese\"},\n",
    "    24: {\"code\": \"fa\", \"name\": \"Persian\"},\n",
    "    25: {\"code\": \"ro\", \"name\": \"Romanian\"},\n",
    "    26: {\"code\": \"ru\", \"name\": \"Russian\"},\n",
    "    27: {\"code\": \"es\", \"name\": \"Spanish\"},\n",
    "    28: {\"code\": \"sw\", \"name\": \"Swahili\"},\n",
    "    29: {\"code\": \"sv\", \"name\": \"Swedish\"},\n",
    "    30: {\"code\": \"sv\", \"name\": \"Swedish\"},\n",
    "    31: {\"code\": \"ta\", \"name\": \"Tamil\"},\n",
    "    32: {\"code\": \"th\", \"name\": \"Thai\"},\n",
    "    33: {\"code\": \"tr\", \"name\": \"Turkish\"},\n",
    "    34: {\"code\": \"ur\", \"name\": \"Urdu\"},\n",
    "    35: {\"code\": \"vi\", \"name\": \"Vietnamese\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2label(code_dict: dict):\n",
    "    return {k: v[\"name\"] for k, v in code_dict.items()}\n",
    "\n",
    "\n",
    "def label2index(code_dict: dict):\n",
    "    return {v[\"name\"]: k for k, v in code_dict.items()}\n",
    "\n",
    "\n",
    "LABEL_TO_INDEX = label2index(code_to_index)\n",
    "INDEX_TO_LABEL = index2label(code_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 0,\n",
       " 'Bulgarian': 1,\n",
       " 'Chinese (Simplified)': 2,\n",
       " 'Danish': 3,\n",
       " 'Dutch': 4,\n",
       " 'English': 5,\n",
       " 'Estonian': 6,\n",
       " 'French': 7,\n",
       " 'German': 8,\n",
       " 'Greek': 18,\n",
       " 'Hindi': 10,\n",
       " 'Indonesian': 11,\n",
       " 'Italian': 16,\n",
       " 'Japanese': 13,\n",
       " 'Kannada': 14,\n",
       " 'Korean': 15,\n",
       " 'Malayalam': 17,\n",
       " 'Persian': 24,\n",
       " 'Polish': 20,\n",
       " 'Portuguese': 23,\n",
       " 'Romanian': 25,\n",
       " 'Russian': 26,\n",
       " 'Spanish': 27,\n",
       " 'Swahili': 28,\n",
       " 'Swedish': 30,\n",
       " 'Tamil': 31,\n",
       " 'Thai': 32,\n",
       " 'Turkish': 33,\n",
       " 'Urdu': 34,\n",
       " 'Vietnamese': 35}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_TO_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Arabic',\n",
       " 1: 'Bulgarian',\n",
       " 2: 'Chinese (Simplified)',\n",
       " 3: 'Danish',\n",
       " 4: 'Dutch',\n",
       " 5: 'English',\n",
       " 6: 'Estonian',\n",
       " 7: 'French',\n",
       " 8: 'German',\n",
       " 9: 'Greek',\n",
       " 10: 'Hindi',\n",
       " 11: 'Indonesian',\n",
       " 12: 'Italian',\n",
       " 13: 'Japanese',\n",
       " 14: 'Kannada',\n",
       " 15: 'Korean',\n",
       " 16: 'Italian',\n",
       " 17: 'Malayalam',\n",
       " 18: 'Greek',\n",
       " 19: 'Persian',\n",
       " 20: 'Polish',\n",
       " 21: 'Portuguese',\n",
       " 22: 'Portuguese',\n",
       " 23: 'Portuguese',\n",
       " 24: 'Persian',\n",
       " 25: 'Romanian',\n",
       " 26: 'Russian',\n",
       " 27: 'Spanish',\n",
       " 28: 'Swahili',\n",
       " 29: 'Swedish',\n",
       " 30: 'Swedish',\n",
       " 31: 'Tamil',\n",
       " 32: 'Thai',\n",
       " 33: 'Turkish',\n",
       " 34: 'Urdu',\n",
       " 35: 'Vietnamese'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INDEX_TO_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Language': 33,\n",
       " 'Text': 'özellikle şehrin en ünlü sakinleri olan geyşa nın son eğitim merkezi olarak ünlü'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = MODEL_NAMES[\"xlm-roberta\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=len(code_to_index),\n",
    "    id2label=INDEX_TO_LABEL,\n",
    "    label2id=LABEL_TO_INDEX,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=36, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sample):\n",
    "    return tokenizer(sample[\"Text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 83358/83358 [00:04<00:00, 16866.69 examples/s]\n",
      "Map: 100%|██████████| 17862/17862 [00:01<00:00, 14543.88 examples/s]\n",
      "Map: 100%|██████████| 17863/17863 [00:01<00:00, 14811.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Language', 'Text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 83358\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Language', 'Text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 17862\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Language', 'Text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 17863\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocessing, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Language': 28,\n",
       " 'Text': 'wa wa nasaha walevi could ya wagonjwa wa wamelewa wamelewa',\n",
       " 'input_ids': [0,\n",
       "  259,\n",
       "  259,\n",
       "  22182,\n",
       "  528,\n",
       "  259,\n",
       "  94201,\n",
       "  5809,\n",
       "  151,\n",
       "  218761,\n",
       "  259,\n",
       "  259,\n",
       "  39,\n",
       "  79870,\n",
       "  259,\n",
       "  39,\n",
       "  79870,\n",
       "  2],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed = tokenized_dataset[\"train\"]\n",
    "val_preprocessed = tokenized_dataset[\"validation\"]\n",
    "test_preprocessed = tokenized_dataset[\"test\"]\n",
    "\n",
    "train_preprocessed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 4.20kB [00:00, 17.2MB/s]\n",
      "Downloading builder script: 6.79kB [00:00, 3.25MB/s]\n",
      "Downloading builder script: 7.56kB [00:00, 5.47MB/s]\n",
      "Downloading builder script: 7.38kB [00:00, 3.86MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation Setup\n",
    "\n",
    "\"\"\"\n",
    "            Predicted\n",
    "            Yes    No\n",
    "Actual  Yes  TP   FN  <- Recall = TP/(TP+FN)\n",
    "        No   FP   TN\n",
    "            ↑\n",
    "        Precision = TP/(TP+FP)\n",
    "\"\"\"\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 \n",
    "EPOCHS = 3  \n",
    "WEIGHT_DECAY = 0.01\n",
    "LEARNING_RATE = 2e-5\n",
    "LOGGING_STEPS = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    report_to=\"wandb\",\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    run_name=\"multilang-classify-xlm-roberta-base\",\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "\n",
    "    compute_metrics=clf_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training\n",
    "from copy import deepcopy\n",
    "\n",
    "bf_model = deepcopy(model)\n",
    "\n",
    "bf_model.to(DEVICE)\n",
    "\n",
    "bf_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bf_predictions = bf_model.generate(\n",
    "        **tokenized_dataset[\"test\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training\n",
    "\n",
    "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    # F1 scores\n",
    "    f1_macro = f1_score(labels, predictions, average=\"macro\")\n",
    "    f1_micro = f1_score(labels, predictions, average=\"micro\")\n",
    "    f1_weighted = f1_score(labels, predictions, average=\"weighted\")\n",
    "\n",
    "    # Precision & Recall\n",
    "    precision_macro = precision_score(labels, predictions, average=\"macro\")\n",
    "    recall_macro = recall_score(labels, predictions, average=\"macro\")\n",
    "\n",
    "    # Top-k accuracy\n",
    "    top3_acc = top_k_accuracy_score(labels, eval_pred[0], k=3)\n",
    "    top5_acc = top_k_accuracy_score(labels, eval_pred[0], k=5)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"top3_accuracy\": top3_acc,\n",
    "        \"top5_accuracy\": top5_acc,\n",
    "    }\n",
    "\n",
    "\n",
    "# For detailed analysis after training:\n",
    "def detailed_evaluation(y_true, y_pred, y_pred_proba, class_names):\n",
    "    # Classification report\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_names, output_dict=True\n",
    "    )\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Per-class F1 scores\n",
    "    per_class_f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    return {\n",
    "        \"classification_report\": report,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"per_class_f1\": per_class_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on DataCollatorWithPadding\n",
    "\n",
    "`DataCollatorWithPadding` in Hugging Face is a utility that handles **dynamic padding** of tokenized sequences in a batch during training or inference. Here's what it does:\n",
    "\n",
    "#### Key Functions:\n",
    "\n",
    "1. **Dynamic Batching**: When you have sequences of different lengths in a batch, it pads shorter sequences to match the longest sequence in that specific batch (not a global maximum)\n",
    "\n",
    "2. **Efficient Memory Usage**: Instead of padding all sequences to a fixed maximum length, it only pads to the longest sequence in each batch, saving memory and computation\n",
    "\n",
    "3. **Automatic Padding Token**: Uses the tokenizer's padding token (usually `[PAD]` or `<pad>`) to fill shorter sequences\n",
    "\n",
    "4. **Attention Mask Handling**: Automatically creates or updates attention masks to ignore padded tokens during model computation\n",
    "\n",
    "#### Example:\n",
    "```python\n",
    "# Without padding - sequences have different lengths:\n",
    "batch = [\n",
    "    [1, 2, 3],           # length 3\n",
    "    [4, 5, 6, 7, 8],     # length 5  \n",
    "    [9, 10]              # length 2\n",
    "]\n",
    "\n",
    "# After DataCollatorWithPadding:\n",
    "padded_batch = [\n",
    "    [1, 2, 3, 0, 0],     # padded to length 5\n",
    "    [4, 5, 6, 7, 8],     # already length 5\n",
    "    [9, 10, 0, 0, 0]     # padded to length 5\n",
    "]\n",
    "# + corresponding attention masks: [1,1,1,0,0], [1,1,1,1,1], [1,1,0,0,0]\n",
    "```\n",
    "\n",
    "#### In our Context:\n",
    "In this multilingual classification notebook, it ensures that when training batches are created from our tokenized text data (which have varying lengths), they're properly padded so the model can process them efficiently as tensors of uniform shape."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
